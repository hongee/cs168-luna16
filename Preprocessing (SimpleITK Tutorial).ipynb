{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on how to open, visualize and extract some features from a .mhd Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Tutorial will show how to:\n",
    "    - Open and read a .mhd image\n",
    "    - Visualize a .mhd image\n",
    "    - Read a list of candidates from a .csv file\n",
    "    - Transform from world coordinates to voxel coordinates\n",
    "    - Extract some features / patches of candidates and visualize them\n",
    "To be able to run this tutorial some python libraries / modules need to be installed:\n",
    "    - Simple ITK: a library for handling and processing medical images\n",
    "    - Numpy: a fundamental package for scientific computing with Python\n",
    "    - PIL (Python Imaging Library): a library for adding image processing capabilities to your Python interpreter \n",
    "    - Matplotlib: a plotting library for the Python programming language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start importing required modules / libraries  using the import command from python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define now a function to:\n",
    "    - Open the image \n",
    "    - Store it into a numpy array\n",
    "    - Extract the following info: Pixel Spacing, Origin\n",
    "This function takes as input the name of the image and returns:\n",
    "    - The array corresponding to the image (numpyImage)\n",
    "    - Origin (numpyOrigin)\n",
    "    - PixelSpacing (numpySpacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_itk_image(filename):\n",
    "    itkimage = sitk.ReadImage(filename)\n",
    "    numpyImage = sitk.GetArrayFromImage(itkimage)\n",
    "     \n",
    "    numpyOrigin = np.array(list(reversed(itkimage.GetOrigin())))\n",
    "    numpySpacing = np.array(list(reversed(itkimage.GetSpacing())))\n",
    "     \n",
    "    return numpyImage, numpyOrigin, numpySpacing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to open and read the list of candidates, we need to use the csv python module. \n",
    "We define now a function to:\n",
    "    - Open a csv file\n",
    "    - Read a csv file\n",
    "    - Save each line of a csv file\n",
    "This functions takes as input the name of the csv file and returns:\n",
    "    - A list of each line of the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(filename):\n",
    "    lines = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        csvreader = csv.reader(f)\n",
    "        for line in csvreader:\n",
    "            lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the coordinates of the candidates are given in World Coordinates, we now need to transform from world coordinates to voxel coordinates. \n",
    "We define now a function to do that. Please note that the transformation below is only valid if there is no rotation component in the transformation matrix. For all CT images in our dataset, there is no rotation component so that this formula can be used. \n",
    "This function takes as inputs:\n",
    "    - The world coordinates\n",
    "    - The origin\n",
    "    - The pixel Spacing\n",
    "This function returns:\n",
    "    - Voxel coordinates (voxelCoord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worldToVoxelCoord(worldCoord, origin, spacing):\n",
    "     \n",
    "    stretchedVoxelCoord = np.absolute(worldCoord - origin)\n",
    "    voxelCoord = stretchedVoxelCoord / spacing\n",
    "    return voxelCoord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to extract now some features from the candidates. We define some normalized planes to extract views from the candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizePlanes(npzarray):\n",
    "     \n",
    "    maxHU = 400.\n",
    "    minHU = -1000.\n",
    " \n",
    "    npzarray = (npzarray - minHU) / (maxHU - minHU)\n",
    "    npzarray[npzarray>1] = 1.\n",
    "    npzarray[npzarray<0] = 0.\n",
    "    return npzarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having defined these auxiliary functions, we can now define the main part of our script.\n",
    "First we:\n",
    "    - Specify the path where the image (img_path) is \n",
    "    - Specificy the path where the file with the list of candidates is (cand_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path  = './data/1.3.6.1.4.1.14519.5.2.1.6279.6001.109002525524522225658609808059.mhd'\n",
    "cand_path = './data/candidates.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function defined in line 2 we can:\n",
    "    - Load the image\n",
    "    - Extract the Origin\n",
    "    - Extract the Pixel Spacing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161, 512, 512)\n",
      "[-194.       -108.300003 -187.699997]\n",
      "[1.25       0.54882801 0.54882801]\n"
     ]
    }
   ],
   "source": [
    "# load image\n",
    "numpyImage, numpyOrigin, numpySpacing = load_itk_image(img_path)\n",
    "print(numpyImage.shape)\n",
    "print(numpyOrigin)\n",
    "print(numpySpacing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function defined in line 3 we can:\n",
    "    - Load the csv file\n",
    "    - Get the candidates \n",
    "Using the function defined in line 4 we can: \n",
    "    - Transform from world to voxel coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222365663678666836860',\n",
       " '-56.08',\n",
       " '-67.85',\n",
       " '-311.92',\n",
       " '0']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load candidates\n",
    "cands = readCSV(cand_path)\n",
    "# get candidates\n",
    "for cand in cands[1:]:\n",
    "    worldCoord = np.asarray([float(cand[3]),float(cand[2]),float(cand[1])])\n",
    "    voxelCoord = worldToVoxelCoord(worldCoord, numpyOrigin, numpySpacing)\n",
    "    voxelWidth = 65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function defined in line 5 we can:\n",
    "    - Extract patch for each candidate in the list\n",
    "    - Visualize each patch\n",
    "    - Save each page as image in .tiff format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FOLDER = './data'\n",
    "datapoints = os.listdir(INPUT_FOLDER)\n",
    "datapoints = set((filter(lambda x: \".mhd\" in x, datapoints)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_img = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0\n",
      "Done 1000\n",
      "Done 2000\n",
      "Done 3000\n",
      "Done 4000\n",
      "Done 5000\n",
      "Done 6000\n",
      "Done 7000\n",
      "Done 8000\n",
      "Done 9000\n",
      "Done 10000\n",
      "Done 11000\n",
      "Done 12000\n",
      "Done 13000\n",
      "Done 14000\n",
      "Done 15000\n",
      "Done 16000\n",
      "Done 17000\n",
      "Done 18000\n",
      "Done 19000\n",
      "Done 20000\n",
      "Done 21000\n",
      "Done 22000\n",
      "Done 23000\n",
      "Done 24000\n",
      "Done 25000\n",
      "Done 26000\n",
      "Done 27000\n",
      "Done 28000\n",
      "Done 29000\n",
      "Done 30000\n",
      "Done 31000\n",
      "Done 32000\n",
      "Done 33000\n",
      "Done 34000\n",
      "Done 35000\n",
      "Done 36000\n",
      "Done 37000\n",
      "Done 38000\n",
      "Done 39000\n",
      "Done 40000\n",
      "Done 41000\n",
      "Done 42000\n",
      "Done 43000\n",
      "Done 44000\n",
      "Done 45000\n",
      "Done 46000\n",
      "Done 47000\n",
      "Done 48000\n",
      "Done 49000\n",
      "Done 50000\n",
      "Done 51000\n",
      "Done 52000\n",
      "Done 53000\n",
      "Done 54000\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "all_data = []\n",
    "for cand in cands[31300:]:\n",
    "    fname = cand[0] + \".mhd\"\n",
    "    if fname not in datapoints:\n",
    "        continue\n",
    "    if i % 1000 == 0:\n",
    "        print(\"Done %d\" % i)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "    img_path = './data/' + fname\n",
    "    if img_path in loaded_img:\n",
    "        numpyImage, numpyOrigin, numpySpacing = loaded_img[img_path]\n",
    "    else:\n",
    "        numpyImage, numpyOrigin, numpySpacing = load_itk_image(img_path)\n",
    "        loaded_img[img_path] = (numpyImage, numpyOrigin, numpySpacing)\n",
    "    \n",
    "    worldCoord = np.asarray([float(cand[3]),float(cand[2]),float(cand[1])])\n",
    "    voxelCoord = worldToVoxelCoord(worldCoord, numpyOrigin, numpySpacing)\n",
    "    voxelWidth = 100\n",
    "    \n",
    "    patch = numpyImage[int(voxelCoord[0]),int(voxelCoord[1]-voxelWidth/2):int(voxelCoord[1]+voxelWidth/2),int(voxelCoord[2]-voxelWidth/2):int(voxelCoord[2]+voxelWidth/2)]\n",
    "    patch = normalizePlanes(patch)\n",
    "\n",
    "    outputDir = 'patches/'\n",
    "    all_data.append(np.append([int(cand[4])], patch.flatten()))\n",
    "    #plt.imshow(patch, cmap='gray')\n",
    "    #plt.show()\n",
    "    #Image.fromarray(patch*255).convert('L').save(os.path.join(outputDir, 'patch_' + str(worldCoord[0]) + '_' + str(worldCoord[1]) + '_' + str(worldCoord[2]) + '.tiff'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-0c47de3a47c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Envs/cs168_project/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "results = np.vstack(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10001,)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_all_data = np.vstack(filter(lambda x: x.shape[0] == 10001, all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./sample_data_2\", f_all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

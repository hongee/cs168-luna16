{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on how to open, visualize and extract some features from a .mhd Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Tutorial will show how to:\n",
    "    - Open and read a .mhd image\n",
    "    - Visualize a .mhd image\n",
    "    - Read a list of candidates from a .csv file\n",
    "    - Transform from world coordinates to voxel coordinates\n",
    "    - Extract some features / patches of candidates and visualize them\n",
    "To be able to run this tutorial some python libraries / modules need to be installed:\n",
    "    - Simple ITK: a library for handling and processing medical images\n",
    "    - Numpy: a fundamental package for scientific computing with Python\n",
    "    - PIL (Python Imaging Library): a library for adding image processing capabilities to your Python interpreter \n",
    "    - Matplotlib: a plotting library for the Python programming language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start importing required modules / libraries  using the import command from python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from PIL import Image\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pandas\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define now a function to:\n",
    "    - Open the image \n",
    "    - Store it into a numpy array\n",
    "    - Extract the following info: Pixel Spacing, Origin\n",
    "This function takes as input the name of the image and returns:\n",
    "    - The array corresponding to the image (numpyImage)\n",
    "    - Origin (numpyOrigin)\n",
    "    - PixelSpacing (numpySpacing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to open and read the list of candidates, we need to use the csv python module. \n",
    "We define now a function to:\n",
    "    - Open a csv file\n",
    "    - Read a csv file\n",
    "    - Save each line of a csv file\n",
    "This functions takes as input the name of the csv file and returns:\n",
    "    - A list of each line of the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8e500c27318b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1034\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Swap columns around to make our lives easier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnp_f_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "np_data = np.vstack(filter(lambda x: x.shape[0] == 1034, data))\n",
    "\n",
    "# Swap columns around to make our lives easier\n",
    "\n",
    "np_f_data = np.hstack((np_data[:,1:2], np_data[:,0:1], np_data[:,2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./sample_data_2\", np_f_data) # Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"resources/luna16_annotations/187/029.xml\", \"resources/luna16_annotations/187/014.xml\", \"resources/luna16_annotations/187/158.xml\", \"resources/luna16_annotations/187/172.xml\", \"resources/luna16_annotations/187/115.xml\", \"resources/luna16_annotations/187/277.xml\", \"resources/luna16_annotations/187/048.xml\", \"resources/luna16_annotations/187/128.xml\", \"resources/luna16_annotations/187/258.xml\", \"resources/luna16_annotations/187/106.xml\", \"resources/luna16_annotations/187/104.xml\", \"resources/luna16_annotations/187/266.xml\", \"resources/luna16_annotations/187/064.xml\", \"resources/luna16_annotations/187/242.xml\", \"resources/luna16_annotations/187/041.xml\", \"resources/luna16_annotations/187/268.xml\", \"resources/luna16_annotations/187/091.xml\", \"resources/luna16_annotations/187/251.xml\", \"resources/luna16_annotations/187/086.xml\", \"resources/luna16_annotations/187/285.xml\", \"resources/luna16_annotations/187/208.xml\", \"resources/luna16_annotations/187/034.xml\", \"resources/luna16_annotations/187/223.xml\", \"resources/luna16_annotations/187/155.xml\", \"resources/luna16_annotations/187/233.xml\", \"resources/luna16_annotations/187/232.xml\", \"resources/luna16_annotations/189/003.xml\", \"resources/luna16_annotations/189/013.xml\", \"resources/luna16_annotations/189/062.xml\", \"resources/luna16_annotations/189/076.xml\", \"resources/luna16_annotations/189/071.xml\", \"resources/luna16_annotations/189/123.xml\", \"resources/luna16_annotations/189/053.xml\", \"resources/luna16_annotations/189/047.xml\", \"resources/luna16_annotations/189/079.xml\", \"resources/luna16_annotations/189/124.xml\", \"resources/luna16_annotations/189/142.xml\", \"resources/luna16_annotations/189/034.xml\", \"resources/luna16_annotations/189/019.xml\", \"resources/luna16_annotations/189/026.xml\", \"resources/luna16_annotations/188/229.xml\", \"resources/luna16_annotations/188/001.xml\", \"resources/luna16_annotations/188/212.xml\", \"resources/luna16_annotations/188/012.xml\", \"resources/luna16_annotations/188/288.xml\", \"resources/luna16_annotations/188/061.xml\", \"resources/luna16_annotations/188/114.xml\", \"resources/luna16_annotations/188/102.xml\", \"resources/luna16_annotations/188/261.xml\", \"resources/luna16_annotations/188/073.xml\", \"resources/luna16_annotations/188/258.xml\", \"resources/luna16_annotations/188/299.xml\", \"resources/luna16_annotations/188/273.xml\", \"resources/luna16_annotations/188/295.xml\", \"resources/luna16_annotations/188/096.xml\", \"resources/luna16_annotations/188/294.xml\", \"resources/luna16_annotations/188/123.xml\", \"resources/luna16_annotations/188/269.xml\", \"resources/luna16_annotations/188/094.xml\", \"resources/luna16_annotations/188/095.xml\", \"resources/luna16_annotations/188/127.xml\", \"resources/luna16_annotations/188/141.xml\", \"resources/luna16_annotations/188/145.xml\", \"resources/luna16_annotations/188/025.xml\", \"resources/luna16_annotations/188/226.xml\", \"resources/luna16_annotations/188/230.xml\", \"resources/luna16_annotations/188/027.xml\", \"resources/luna16_annotations/188/225.xml\", \"resources/luna16_annotations/186/175.xml\", \"resources/luna16_annotations/186/164.xml\", \"resources/luna16_annotations/186/213.xml\", \"resources/luna16_annotations/186/205.xml\", \"resources/luna16_annotations/186/129.xml\", \"resources/luna16_annotations/186/076.xml\", \"resources/luna16_annotations/186/249.xml\", \"resources/luna16_annotations/186/070.xml\", \"resources/luna16_annotations/186/244.xml\", \"resources/luna16_annotations/186/293.xml\", \"resources/luna16_annotations/186/195.xml\", \"resources/luna16_annotations/186/009.xml\", \"resources/luna16_annotations/186/191.xml\", \"resources/luna16_annotations/185/215.xml\", \"resources/luna16_annotations/185/172.xml\", \"resources/luna16_annotations/185/248.xml\", \"resources/luna16_annotations/185/072.xml\", \"resources/luna16_annotations/185/243.xml\", \"resources/luna16_annotations/185/094.xml\", \"resources/luna16_annotations/185/278.xml\", \"resources/luna16_annotations/185/085.xml\", \"resources/luna16_annotations/185/147.xml\"]'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(xml_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset0 = set(xml_paths) # These are the paths to ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  resources/luna16_annotations/157/162.xml\n",
      "0 :  resources/luna16_annotations/157/163.xml\n",
      "0 :  resources/luna16_annotations/157/161.xml\n",
      "0 :  resources/luna16_annotations/157/160.xml\n",
      "0 :  resources/luna16_annotations/157/158.xml\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-173-0bf5abdc40b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxml_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_lidc_annotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-163-6c80268e2ae7>\u001b[0m in \u001b[0;36mprocess_lidc_annotations\u001b[0;34m(only_patient, agreement_threshold, ignore)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\": \"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mxml_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextended\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_lidc_xml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxml_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_patient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0monly_patient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magreement_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magreement_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mpaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-115-9b27b497d158>\u001b[0m in \u001b[0;36mload_lidc_xml\u001b[0;34m(xml_path, agreement_threshold, only_patient, save_nodules)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxml_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmarkup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxml_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mxml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"xml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLidcReadMessage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/cs168_project/lib/python3.6/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mParserRejectedMarkup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/cs168_project/lib/python3.6/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m_feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/cs168_project/lib/python3.6/site-packages/bs4/builder/_lxml.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarkup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mUnicodeDecodeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParserError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._FeedParser.feed\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._FeedParser.feed\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parsertarget.pxi\u001b[0m in \u001b[0;36mlxml.etree._TargetParserContext._handleParseResult\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parsertarget.pxi\u001b[0m in \u001b[0;36mlxml.etree._TargetParserContext._handleParseResult\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/etree.pyx\u001b[0m in \u001b[0;36mlxml.etree._ExceptionContext._raise_if_stored\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/saxparser.pxi\u001b[0m in \u001b[0;36mlxml.etree._handleSaxTargetStart\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/saxparser.pxi\u001b[0m in \u001b[0;36mlxml.etree._callTargetSaxStart\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parsertarget.pxi\u001b[0m in \u001b[0;36mlxml.etree._PythonSaxParserTarget._handleSaxStart\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Envs/cs168_project/lib/python3.6/site-packages/bs4/builder/_lxml.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, name, attrs, nsmap)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getNsTag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mnsprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prefix_for_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prefix_for_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/cs168_project/lib/python3.6/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36mhandle_starttag\u001b[0;34m(self, name, namespace, nsprefix, attrs)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         tag = Tag(self, self.builder, name, namespace, nsprefix, attrs,\n\u001b[0;32m--> 465\u001b[0;31m                   self.currentTag, self._most_recent_element)\n\u001b[0m\u001b[1;32m    466\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/cs168_project/lib/python3.6/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parser, builder, name, namespace, prefix, attrs, parent, previous, is_xml)\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# We don't actually store the parser object: that lets extracted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;31m# chunks be garbage-collected.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No value provided for new tag's name.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# THIS IS THE MAIN FUNCTION\n",
    "data, xml_paths = process_lidc_annotations(ignore=subset0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FOLDER = './subset9/'\n",
    "datapoints = os.listdir(INPUT_FOLDER)\n",
    "datapoints = set((filter(lambda x: \".mhd\" in x, datapoints)))\n",
    "\n",
    "def find_mhd_file(patient_id):\n",
    "    fname = patient_id + '.mhd'\n",
    "    if fname in datapoints:\n",
    "        img_path = INPUT_FOLDER + fname\n",
    "        return img_path\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_lidc_annotations(only_patient=None, agreement_threshold=0, ignore=set()):\n",
    "    # lines.append(\",\".join())\n",
    "    file_no = 0\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    all_lines = []\n",
    "    total = []\n",
    "    paths = []\n",
    "    for anno_dir in [d for d in glob.glob(\"resources/luna16_annotations/*\") if os.path.isdir(d)]:\n",
    "        xml_paths = glob.glob(anno_dir + \"/*.xml\")\n",
    "        for xml_path in xml_paths:\n",
    "            if xml_path in ignore:\n",
    "                continue\n",
    "            print(file_no, \": \",  xml_path)\n",
    "            pos, neg, extended, data = load_lidc_xml(xml_path=xml_path, only_patient=only_patient, agreement_threshold=agreement_threshold)\n",
    "            if data is not None:\n",
    "                paths.append(xml_path)\n",
    "                total.extend(data)\n",
    "                print(len(total))\n",
    "            #if pos is not None:\n",
    "            #    print(\"FOUND \" + xml_path)\n",
    "            #    paths.append((xml_path, (pos, neg, extended)))\n",
    "            #    break\n",
    "    return total, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lidc_xml(xml_path, agreement_threshold=0, only_patient=None, save_nodules=False):\n",
    "    pos_lines = []\n",
    "    neg_lines = []\n",
    "    extended_lines = []\n",
    "    data = []\n",
    "    with open(xml_path, 'r') as xml_file:\n",
    "        markup = xml_file.read()\n",
    "    xml = BeautifulSoup(markup, features=\"xml\")\n",
    "    if xml.LidcReadMessage is None:\n",
    "        return None, None, None, None\n",
    "    patient_id = xml.LidcReadMessage.ResponseHeader.SeriesInstanceUid.text\n",
    "    if only_patient is not None:\n",
    "        if only_patient != patient_id:\n",
    "            return None, None, None, None\n",
    "\n",
    "    #print(patient_id)\n",
    "    src_path = find_mhd_file(patient_id)\n",
    "    if src_path is None:\n",
    "        return None, None, None, None\n",
    "\n",
    "    itk_img = sitk.ReadImage(src_path)\n",
    "    img_array = sitk.GetArrayFromImage(itk_img)\n",
    "    num_z, height, width = img_array.shape        #heightXwidth constitute the transverse plane\n",
    "    origin = np.array(itk_img.GetOrigin())      # x,y,z  Origin in world coordinates (mm)\n",
    "    spacing = np.array(itk_img.GetSpacing())    # spacing of voxels in world coor. (mm)\n",
    "    rescale = spacing / 1.00\n",
    "    \n",
    "    reading_sessions = xml.LidcReadMessage.find_all(\"readingSession\")\n",
    "    for reading_session in reading_sessions:\n",
    "        # print(\"Sesion\")\n",
    "        nodules = reading_session.find_all(\"unblindedReadNodule\")\n",
    "        for nodule in nodules:\n",
    "            nodule_id = nodule.noduleID.text\n",
    "            # print(\"  \", nodule.noduleID)\n",
    "            rois = nodule.find_all(\"roi\")\n",
    "            x_min = y_min = z_min = 999999\n",
    "            x_max = y_max = z_max = -999999\n",
    "            if len(rois) < 2:\n",
    "                continue\n",
    "\n",
    "            for roi in rois:\n",
    "                z_pos = float(roi.imageZposition.text)\n",
    "                z_min = min(z_min, z_pos)\n",
    "                z_max = max(z_max, z_pos)\n",
    "                edge_maps = roi.find_all(\"edgeMap\")\n",
    "                for edge_map in edge_maps:\n",
    "                    x = int(edge_map.xCoord.text)\n",
    "                    y = int(edge_map.yCoord.text)\n",
    "                    x_min = min(x_min, x)\n",
    "                    y_min = min(y_min, y)\n",
    "                    x_max = max(x_max, x)\n",
    "                    y_max = max(y_max, y)\n",
    "                if x_max == x_min:\n",
    "                    continue\n",
    "                if y_max == y_min:\n",
    "                    continue\n",
    "\n",
    "            x_diameter = x_max - x_min\n",
    "            x_center = x_min + x_diameter / 2\n",
    "            y_diameter = y_max - y_min\n",
    "            y_center = y_min + y_diameter / 2\n",
    "            z_diameter = z_max - z_min\n",
    "            z_center = z_min + z_diameter / 2\n",
    "            z_center -= origin[2]\n",
    "            z_center /= spacing[2]\n",
    "            \n",
    "            #print(\"X Y Z\")\n",
    "            #print(x_center, y_center, z_center)\n",
    "\n",
    "            x_center_perc = round(x_center / img_array.shape[2], 4)\n",
    "            y_center_perc = round(y_center / img_array.shape[1], 4)\n",
    "            z_center_perc = round(z_center / img_array.shape[0], 4)\n",
    "            diameter = max(x_diameter , y_diameter)\n",
    "            diameter_perc = round(max(x_diameter / img_array.shape[2], y_diameter / img_array.shape[1]), 4)\n",
    "\n",
    "            if nodule.characteristics is None:\n",
    "                print(\"!!!!Nodule:\", nodule_id, \" has no charecteristics\")\n",
    "                continue\n",
    "            if nodule.characteristics.malignancy is None:\n",
    "                print(\"!!!!Nodule:\", nodule_id, \" has no malignacy\")\n",
    "                continue\n",
    "\n",
    "            malignacy = nodule.characteristics.malignancy.text\n",
    "            sphericiy = nodule.characteristics.sphericity.text\n",
    "            margin = nodule.characteristics.margin.text\n",
    "            spiculation = nodule.characteristics.spiculation.text\n",
    "            texture = nodule.characteristics.texture.text\n",
    "            calcification = nodule.characteristics.calcification.text\n",
    "            internal_structure = nodule.characteristics.internalStructure.text\n",
    "            lobulation = nodule.characteristics.lobulation.text\n",
    "            subtlety = nodule.characteristics.subtlety.text\n",
    "            \n",
    "            #print(img_array.shape)\n",
    "            #print(int(z_center))\n",
    "            #print(int(x_center-16))\n",
    "            img_crop = img_array[int(z_center), int(y_center-16):int(y_center+16), int(x_center-16):int(x_center+16)]\n",
    "            img_crop = normalizePlanes(img_crop)\n",
    "            #plt.imshow(img_crop, cmap='gray')\n",
    "            #plt.show()\n",
    "\n",
    "            line = [nodule_id, x_center_perc, y_center_perc, z_center_perc, diameter_perc, malignacy]\n",
    "            extended_line = [patient_id, nodule_id, x_center_perc, y_center_perc, z_center_perc, diameter_perc, malignacy, sphericiy, margin, spiculation, texture, calcification, internal_structure, lobulation, subtlety ]\n",
    "            data_line = [diameter_perc, malignacy, sphericiy, margin, spiculation, texture, calcification, internal_structure, lobulation, subtlety] \n",
    "            \n",
    "            \n",
    "            data.append(np.append([float(i) for i in data_line], img_crop))\n",
    "            \n",
    "            #pos_lines.append(line)\n",
    "            #extended_lines.append(extended_line)\n",
    "\n",
    "        nonNodules = reading_session.find_all(\"nonNodule\")\n",
    "        for nonNodule in nonNodules:\n",
    "            z_center = float(nonNodule.imageZposition.text)\n",
    "            z_center -= origin[2]\n",
    "            z_center /= spacing[2]\n",
    "            x_center = int(nonNodule.locus.xCoord.text)\n",
    "            y_center = int(nonNodule.locus.yCoord.text)\n",
    "            nodule_id = nonNodule.nonNoduleID.text\n",
    "            x_center_perc = round(x_center / img_array.shape[2], 4)\n",
    "            y_center_perc = round(y_center / img_array.shape[1], 4)\n",
    "            z_center_perc = round(z_center / img_array.shape[0], 4)\n",
    "            diameter_perc = round(max(6 / img_array.shape[2], 6 / img_array.shape[1]), 4)\n",
    "            # print(\"Non nodule!\", z_center)\n",
    "            line = [nodule_id, x_center_perc, y_center_perc, z_center_perc, diameter_perc, 0]\n",
    "            neg_lines.append(line)\n",
    "\n",
    "#     if agreement_threshold > 1:\n",
    "#         filtered_lines = []\n",
    "#         for pos_line1 in pos_lines:\n",
    "#             id1 = pos_line1[0]\n",
    "#             x1 = pos_line1[1]\n",
    "#             y1 = pos_line1[2]\n",
    "#             z1 = pos_line1[3]\n",
    "#             d1 = pos_line1[4]\n",
    "#             overlaps = 0\n",
    "#             for pos_line2 in pos_lines:\n",
    "#                 id2 = pos_line2[0]\n",
    "#                 if id1 == id2:\n",
    "#                     continue\n",
    "#                 x2 = pos_line2[1]\n",
    "#                 y2 = pos_line2[2]\n",
    "#                 z2 = pos_line2[3]\n",
    "#                 d2 = pos_line1[4]\n",
    "#                 dist = math.sqrt(math.pow(x1 - x2, 2) + math.pow(y1 - y2, 2) + math.pow(z1 - z2, 2))\n",
    "#                 if dist < d1 or dist < d2:\n",
    "#                     overlaps += 1\n",
    "#             if overlaps >= agreement_threshold:\n",
    "#                 filtered_lines.append(pos_line1)\n",
    "#             # else:\n",
    "#             #     print(\"Too few overlaps\")\n",
    "#         pos_lines = filtered_lines\n",
    "\n",
    "    #df_annos = pandas.DataFrame(pos_lines, columns=[\"anno_index\", \"coord_x\", \"coord_y\", \"coord_z\", \"diameter\", \"malscore\"])\n",
    "    #df_annos.to_csv(\"out/\" + patient_id + \"_annos_pos_lidc.csv\", index=False)\n",
    "    #df_neg_annos = pandas.DataFrame(neg_lines, columns=[\"anno_index\", \"coord_x\", \"coord_y\", \"coord_z\", \"diameter\", \"malscore\"])\n",
    "    #df_neg_annos.to_csv(\"out/\" + patient_id + \"_annos_neg_lidc.csv\", index=False)\n",
    "\n",
    "    # return [patient_id, spacing[0], spacing[1], spacing[2]]\n",
    "    return pos_lines, neg_lines, extended_lines, data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizePlanes(npzarray):\n",
    "     \n",
    "    maxHU = 400.\n",
    "    minHU = -1000.\n",
    " \n",
    "    npzarray = (npzarray - minHU) / (maxHU - minHU)\n",
    "    npzarray[npzarray>1] = 1.\n",
    "    npzarray[npzarray<0] = 0.\n",
    "    return npzarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE FOLLOWING CODE IS NOT USED ANY MORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_itk_image(filename):\n",
    "    itkimage = sitk.ReadImage(filename)\n",
    "    numpyImage = sitk.GetArrayFromImage(itkimage)\n",
    "     \n",
    "    numpyOrigin = np.array(list(reversed(itkimage.GetOrigin())))\n",
    "    numpySpacing = np.array(list(reversed(itkimage.GetSpacing())))\n",
    "     \n",
    "    return numpyImage, numpyOrigin, numpySpacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(filename):\n",
    "    lines = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        csvreader = csv.reader(f)\n",
    "        for line in csvreader:\n",
    "            lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the coordinates of the candidates are given in World Coordinates, we now need to transform from world coordinates to voxel coordinates. \n",
    "We define now a function to do that. Please note that the transformation below is only valid if there is no rotation component in the transformation matrix. For all CT images in our dataset, there is no rotation component so that this formula can be used. \n",
    "This function takes as inputs:\n",
    "    - The world coordinates\n",
    "    - The origin\n",
    "    - The pixel Spacing\n",
    "This function returns:\n",
    "    - Voxel coordinates (voxelCoord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worldToVoxelCoord(worldCoord, origin, spacing):\n",
    "     \n",
    "    stretchedVoxelCoord = np.absolute(worldCoord - origin)\n",
    "    voxelCoord = stretchedVoxelCoord / spacing\n",
    "    return voxelCoord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to extract now some features from the candidates. We define some normalized planes to extract views from the candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function defined in line 5 we can:\n",
    "    - Extract patch for each candidate in the list\n",
    "    - Visualize each patch\n",
    "    - Save each page as image in .tiff format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_img = dict()\n",
    "cands = readCSV(\"./data/candidates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0\n",
      "(124, 512, 512)\n",
      "[ 54.76101806 187.20844995 361.89670584]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "all_data = []\n",
    "for cand in cands[31300:]:\n",
    "    fname = cand[0] + \".mhd\"\n",
    "    if fname not in datapoints:\n",
    "        continue\n",
    "    if i % 1000 == 0:\n",
    "        print(\"Done %d\" % i)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "    img_path = './data/' + fname\n",
    "    if img_path in loaded_img:\n",
    "        numpyImage, numpyOrigin, numpySpacing = loaded_img[img_path]\n",
    "    else:\n",
    "        numpyImage, numpyOrigin, numpySpacing = load_itk_image(img_path)\n",
    "        loaded_img[img_path] = (numpyImage, numpyOrigin, numpySpacing)\n",
    "    \n",
    "    \n",
    "    worldCoord = np.asarray([float(cand[3]),float(cand[2]),float(cand[1])])\n",
    "    voxelCoord = worldToVoxelCoord(worldCoord, numpyOrigin, numpySpacing)\n",
    "    voxelWidth = 100\n",
    "    \n",
    "    print(numpyImage.shape)\n",
    "    print(voxelCoord)\n",
    "    break\n",
    "\n",
    "    \n",
    "    patch = numpyImage[int(voxelCoord[0]),int(voxelCoord[1]-voxelWidth/2):int(voxelCoord[1]+voxelWidth/2),int(voxelCoord[2]-voxelWidth/2):int(voxelCoord[2]+voxelWidth/2)]\n",
    "    patch = normalizePlanes(patch)\n",
    "\n",
    "    outputDir = 'patches/'\n",
    "    all_data.append(np.append([int(cand[4])], patch.flatten()))\n",
    "    #plt.imshow(patch, cmap='gray')\n",
    "    #plt.show()\n",
    "    #Image.fromarray(patch*255).convert('L').save(os.path.join(outputDir, 'patch_' + str(worldCoord[0]) + '_' + str(worldCoord[1]) + '_' + str(worldCoord[2]) + '.tiff'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-0c47de3a47c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Envs/cs168_project/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "results = np.vstack(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10001,)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_all_data = np.vstack(filter(lambda x: x.shape[0] == 10001, all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./sample_data_2\", f_all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
